name: CI/CD for Airflow and Spark

on:
  push:
    branches:
      - dev/crawling/saramin

jobs:
  build-and-push:
    name: Build and Push Docker Images to AWS ECR
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Log in to Amazon ECR
        id: login-ecr
        run: |
          aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/u5b2p7i3

      - name: Build and Push Airflow Image
        run: |
          docker build -t public.ecr.aws/u5b2p7i3/job_scanner/test_repo:airflow-latest -f ./airflow/Dockerfile-airflow .
          docker push public.ecr.aws/u5b2p7i3/job_scanner/test_repo:airflow-latest

      - name: Build and Push Spark Image
        run: |
          docker build -t public.ecr.aws/u5b2p7i3/job_scanner/test_repo:spark-latest -f ./spark/Dockerfile-spark .
          docker push public.ecr.aws/u5b2p7i3/job_scanner/test_repo:spark-latest

  deploy:
    name: Deploy to EC2
    runs-on: ubuntu-latest
    needs: build-and-push

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Ensure Docker is Installed on EC2
        run: |
          ssh -i ${{ secrets.EC2_PRIVATE_KEY }} ubuntu@${{ secrets.EC2_PUBLIC_IP }} << EOF
            if ! command -v docker &> /dev/null; then
              sudo apt-get update
              sudo apt-get install -y docker.io
              sudo systemctl start docker
              sudo systemctl enable docker
            fi
          EOF

      - name: Deploy Airflow and Spark on EC2
        run: |
          ssh -i ${{ secrets.EC2_PRIVATE_KEY }} ubuntu@${{ secrets.EC2_PUBLIC_IP }} << EOF
            docker pull public.ecr.aws/u5b2p7i3/job_scanner/test_repo:airflow-latest
            docker pull public.ecr.aws/u5b2p7i3/job_scanner/test_repo:spark-latest

            mkdir -p ~/deploy
            echo "
            version: '3.8'
            services:
              airflow:
                image: public.ecr.aws/u5b2p7i3/job_scanner/test_repo:airflow-latest
                ports:
                  - '8080:8080'

              spark-master:
                image: public.ecr.aws/u5b2p7i3/job_scanner/test_repo:spark-latest
                ports:
                  - '7077:7077'
                  - '4040:4040'

              spark-worker:
                image: public.ecr.aws/u5b2p7i3/job_scanner/test_repo:spark-latest
                environment:
                  SPARK_MODE: worker
                  SPARK_MASTER_URL: spark://spark-master:7077
            " > ~/deploy/docker-compose.yml

            docker-compose -f ~/deploy/docker-compose.yml up -d
          EOF

